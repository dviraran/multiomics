# =============================================================================
# Foundational Cross-Omics Correlations and Concordance Analysis
# =============================================================================
# This script runs BEFORE advanced integration methods (MOFA, DIABLO, SNF)
# to establish foundational understanding of cross-omics relationships.
#
# Analyses:
#   1. Cross-omics feature correlations (pairwise, partial)
#   2. Sample-level concordance across omics
#   3. Pathway overlap analysis
#   4. Cross-omics co-expression modules
# =============================================================================

#' Main function: Run foundational cross-omics analysis
#' @param mae_data MultiAssayExperiment data from create_multiassay_experiment()
#' @param config Pipeline configuration
#' @return List containing all foundational analysis results
run_foundational_analysis <- function(mae_data, config) {
  log_message("=== Running Foundational Cross-Omics Analysis ===")
  log_message("This runs BEFORE integration methods to understand basic relationships")

  results <- list()
  harmonized <- mae_data$harmonized_omics
  omics_names <- names(harmonized)

  # Check we have at least 2 omics

  if (length(omics_names) < 2) {
    log_message("Need at least 2 omics for cross-omics analysis. Skipping.")
    return(NULL)
  }

  # Get foundational config with defaults
  fc <- get_foundational_config(config)

  # 1. Cross-omics feature correlations
  results$feature_correlations <- tryCatch(
    compute_crossomics_feature_correlations(harmonized, mae_data$gene_mapping, fc, config),
    error = function(e) {
      log_message("WARNING: Feature correlation analysis failed: ", conditionMessage(e))
      NULL
    }
  )

  # 2. Sample-level concordance
  results$sample_concordance <- tryCatch(
    compute_sample_concordance(harmonized, mae_data$metadata, fc, config),
    error = function(e) {
      log_message("WARNING: Sample concordance analysis failed: ", conditionMessage(e))
      NULL
    }
  )

  # 3. Pathway overlap analysis
  results$pathway_overlap <- tryCatch(
    analyze_pathway_overlap(harmonized, mae_data$gene_mapping, fc, config),
    error = function(e) {
      log_message("WARNING: Pathway overlap analysis failed: ", conditionMessage(e))
      NULL
    }
  )

  # 4. Cross-omics module detection (if enabled)
  if (fc$module_detection) {
    results$crossomics_modules <- tryCatch(
      find_crossomics_modules(harmonized, mae_data$gene_mapping, fc, config),
      error = function(e) {
        log_message("WARNING: Module detection failed: ", conditionMessage(e))
        NULL
      }
    )
  }

  # Generate summary
  results$summary <- tryCatch(
    summarize_foundational_results(results, config),
    error = function(e) {
      log_message("WARNING: Summary generation failed: ", conditionMessage(e))
      list(status = "partial", error = conditionMessage(e))
    }
  )

  log_message("=== Foundational Analysis Complete ===")
  return(results)
}

#' Get foundational analysis configuration with defaults
get_foundational_config <- function(config) {
  fc <- config$foundational %||% list()

  list(
    run_foundational = fc$run_foundational %||% TRUE,
    correlation_method = fc$correlation_method %||% "spearman",
    partial_correlations = fc$partial_correlations %||% TRUE,
    confounder_columns = fc$confounder_columns %||% NULL,
    min_correlation = fc$min_correlation %||% 0.3,
    fdr_threshold = fc$fdr_threshold %||% 0.05,
    module_detection = fc$module_detection %||% TRUE,
    min_common_features = fc$min_common_features %||% 50,
    top_variable_features = fc$top_variable_features %||% 2000
  )
}

# =============================================================================
# 1. Cross-Omics Feature Correlations
# =============================================================================

#' Compute cross-omics feature correlations
#' @param harmonized List of harmonized omics data
#' @param gene_mapping Gene mapping table for cross-omics matching
#' @param fc Foundational config
#' @param config Full config
compute_crossomics_feature_correlations <- function(harmonized, gene_mapping, fc, config) {
  log_message("Computing cross-omics feature correlations...")

  omics_names <- names(harmonized)
  results <- list()

  # Generate all pairwise combinations
  pairs <- combn(omics_names, 2, simplify = FALSE)

  for (pair in pairs) {
    omics1 <- pair[1]
    omics2 <- pair[2]
    pair_name <- paste(omics1, omics2, sep = "_vs_")

    log_message("Processing: ", omics1, " vs ", omics2)

    # Get matrices and find common features
    mat1 <- harmonized[[omics1]]$normalized_matrix
    mat2 <- harmonized[[omics2]]$normalized_matrix

    # Get common samples
    common_samples <- intersect(colnames(mat1), colnames(mat2))
    if (length(common_samples) < 5) {
      log_message("  Insufficient common samples (", length(common_samples), "). Skipping.")
      next
    }

    mat1 <- mat1[, common_samples, drop = FALSE]
    mat2 <- mat2[, common_samples, drop = FALSE]

    # Map features to common identifiers (gene symbols)
    mapping_result <- map_features_to_common_ids(
      mat1, mat2, omics1, omics2, gene_mapping
    )

    if (is.null(mapping_result) || mapping_result$n_common < fc$min_common_features) {
      log_message("  Insufficient common features. Skipping.")
      next
    }

    # Compute correlations
    pair_result <- compute_pairwise_correlations(
      mapping_result$mat1_matched,
      mapping_result$mat2_matched,
      mapping_result$common_ids,
      fc, config
    )

    pair_result$omics1 <- omics1
    pair_result$omics2 <- omics2
    pair_result$n_samples <- length(common_samples)

    # Compute partial correlations if confounders specified
    if (fc$partial_correlations && !is.null(fc$confounder_columns)) {
      metadata <- harmonized[[omics1]]$metadata %||% NULL
      if (!is.null(metadata)) {
        pair_result$partial <- compute_partial_correlations(
          mapping_result$mat1_matched,
          mapping_result$mat2_matched,
          mapping_result$common_ids,
          metadata[common_samples, , drop = FALSE],
          fc, config
        )
      }
    }

    # Build correlation network
    pair_result$network <- build_correlation_network(
      pair_result$correlations, fc, config
    )

    # Save results
    save_pairwise_correlation_results(pair_result, pair_name, config)

    results[[pair_name]] <- pair_result
  }

  # Check if we have any results
  pair_names <- setdiff(names(results), "summary")
  if (length(pair_names) == 0) {
    log_message("No cross-omics correlations could be computed.")
    return(list(
      summary = data.frame(
        pair = character(),
        omics1 = character(),
        omics2 = character(),
        n_features = integer(),
        n_samples = integer(),
        mean_correlation = numeric(),
        median_correlation = numeric(),
        n_significant = integer(),
        pct_positive = numeric(),
        stringsAsFactors = FALSE
      )
    ))
  }

  # Create summary
  results$summary <- summarize_correlation_results(results, config)

  # Generate visualizations
  plot_correlation_overview(results, config)

  return(results)
}

#' Map features from two omics to common identifiers
map_features_to_common_ids <- function(mat1, mat2, omics1, omics2, gene_mapping) {
  if (is.null(gene_mapping)) {
    # Try direct matching by rownames
    common_ids <- intersect(rownames(mat1), rownames(mat2))
    if (length(common_ids) == 0) return(NULL)

    return(list(
      mat1_matched = mat1[common_ids, , drop = FALSE],
      mat2_matched = mat2[common_ids, , drop = FALSE],
      common_ids = common_ids,
      n_common = length(common_ids)
    ))
  }

  # Use gene mapping
  map1 <- gene_mapping[gene_mapping$omics == omics1, ]
  map2 <- gene_mapping[gene_mapping$omics == omics2, ]

  # Find common gene symbols
  common_symbols <- intersect(map1$gene_symbol, map2$gene_symbol)
  common_symbols <- common_symbols[!is.na(common_symbols) & common_symbols != ""]

  if (length(common_symbols) == 0) return(NULL)

  # Get feature IDs for each omics
  features1 <- map1$feature_id[match(common_symbols, map1$gene_symbol)]
  features2 <- map2$feature_id[match(common_symbols, map2$gene_symbol)]

  # Filter to features present in matrices
  valid_idx <- features1 %in% rownames(mat1) & features2 %in% rownames(mat2)

  if (sum(valid_idx) == 0) return(NULL)

  common_symbols <- common_symbols[valid_idx]
  features1 <- features1[valid_idx]
  features2 <- features2[valid_idx]

  list(
    mat1_matched = mat1[features1, , drop = FALSE],
    mat2_matched = mat2[features2, , drop = FALSE],
    common_ids = common_symbols,
    n_common = length(common_symbols)
  )
}

#' Compute pairwise correlations between matched features
compute_pairwise_correlations <- function(mat1, mat2, feature_ids, fc, config) {
  n_features <- length(feature_ids)
  n_samples <- ncol(mat1)

  # Initialize results
  correlations <- numeric(n_features)
  pvalues <- numeric(n_features)
  names(correlations) <- feature_ids
  names(pvalues) <- feature_ids

  # Compute correlations
  for (i in seq_len(n_features)) {
    x <- mat1[i, ]
    y <- mat2[i, ]

    # Skip if no variance
    if (sd(x, na.rm = TRUE) == 0 || sd(y, na.rm = TRUE) == 0) {
      correlations[i] <- NA
      pvalues[i] <- NA
      next
    }

    # Correlation test
    ct <- tryCatch({
      cor.test(x, y, method = fc$correlation_method, use = "pairwise.complete.obs")
    }, error = function(e) NULL)

    if (!is.null(ct)) {
      correlations[i] <- ct$estimate
      pvalues[i] <- ct$p.value
    } else {
      correlations[i] <- NA
      pvalues[i] <- NA
    }
  }

  # Adjust p-values
  padj <- p.adjust(pvalues, method = "BH")

  # Create results data frame
  cor_df <- data.frame(
    feature_id = feature_ids,
    correlation = correlations,
    pvalue = pvalues,
    padj = padj,
    significant = padj < fc$fdr_threshold & abs(correlations) >= fc$min_correlation,
    stringsAsFactors = FALSE
  )

  # Summary statistics
  valid_cors <- correlations[!is.na(correlations)]
  summary_stats <- list(
    n_features = n_features,
    n_valid = length(valid_cors),
    mean_cor = mean(valid_cors),
    median_cor = median(valid_cors),
    sd_cor = sd(valid_cors),
    n_positive = sum(valid_cors > 0),
    n_negative = sum(valid_cors < 0),
    n_significant = sum(cor_df$significant, na.rm = TRUE),
    pct_positive = 100 * mean(valid_cors > 0)
  )

  log_message("  Computed ", length(valid_cors), " correlations: ",
              "mean=", round(summary_stats$mean_cor, 3),
              ", median=", round(summary_stats$median_cor, 3),
              ", ", summary_stats$n_significant, " significant")

  list(
    correlations = correlations,
    pvalues = pvalues,
    padj = padj,
    cor_df = cor_df,
    summary = summary_stats
  )
}

#' Compute partial correlations controlling for confounders
compute_partial_correlations <- function(mat1, mat2, feature_ids, metadata, fc, config) {
  log_message("  Computing partial correlations controlling for: ",
              paste(fc$confounder_columns, collapse = ", "))

  # Check if ppcor is available
  if (!requireNamespace("ppcor", quietly = TRUE)) {
    log_message("  ppcor package not available. Skipping partial correlations.")
    return(NULL)
  }

  # Get confounder matrix
  confounder_cols <- intersect(fc$confounder_columns, colnames(metadata))
  if (length(confounder_cols) == 0) {
    log_message("  No confounder columns found in metadata. Skipping.")
    return(NULL)
  }

  # Prepare confounder matrix (numeric encoding)
  Z <- as.data.frame(metadata[, confounder_cols, drop = FALSE])
  for (col in colnames(Z)) {
    if (is.character(Z[[col]]) || is.factor(Z[[col]])) {
      Z[[col]] <- as.numeric(as.factor(Z[[col]]))
    }
  }
  Z <- as.matrix(Z)

  n_features <- length(feature_ids)
  partial_cors <- numeric(n_features)
  partial_pvals <- numeric(n_features)
  names(partial_cors) <- feature_ids
  names(partial_pvals) <- feature_ids

  for (i in seq_len(n_features)) {
    x <- mat1[i, ]
    y <- mat2[i, ]

    # Skip if no variance
    if (sd(x, na.rm = TRUE) == 0 || sd(y, na.rm = TRUE) == 0) {
      partial_cors[i] <- NA
      partial_pvals[i] <- NA
      next
    }

    # Partial correlation
    pt <- tryCatch({
      data_mat <- cbind(x, y, Z)
      complete_idx <- complete.cases(data_mat)
      if (sum(complete_idx) < 10) return(NULL)

      ppcor::pcor.test(x[complete_idx], y[complete_idx], Z[complete_idx, , drop = FALSE],
                       method = fc$correlation_method)
    }, error = function(e) NULL)

    if (!is.null(pt)) {
      partial_cors[i] <- pt$estimate
      partial_pvals[i] <- pt$p.value
    } else {
      partial_cors[i] <- NA
      partial_pvals[i] <- NA
    }
  }

  partial_padj <- p.adjust(partial_pvals, method = "BH")

  partial_df <- data.frame(
    feature_id = feature_ids,
    partial_correlation = partial_cors,
    partial_pvalue = partial_pvals,
    partial_padj = partial_padj,
    stringsAsFactors = FALSE
  )

  valid_pcors <- partial_cors[!is.na(partial_cors)]
  log_message("  Partial correlations: mean=", round(mean(valid_pcors), 3),
              ", median=", round(median(valid_pcors), 3))

  list(
    partial_correlations = partial_cors,
    partial_df = partial_df,
    confounders = confounder_cols
  )
}

#' Build correlation network from significant correlations
build_correlation_network <- function(cor_results, fc, config) {
  cor_df <- cor_results$cor_df

  # Filter to significant correlations
  sig_df <- cor_df[cor_df$significant == TRUE & !is.na(cor_df$significant), ]

  if (nrow(sig_df) == 0) {
    log_message("  No significant correlations for network. Skipping.")
    return(NULL)
  }

  log_message("  Building network from ", nrow(sig_df), " significant correlations")

  # Check if igraph is available
  if (!requireNamespace("igraph", quietly = TRUE)) {
    log_message("  igraph package not available. Returning edge list only.")
    return(list(edges = sig_df, graph = NULL))
  }

  # Create edge list (self-loops represent cross-omics correlation)
  # For visualization, we create nodes for each feature in each omics
  edges <- data.frame(
    from = paste0("omics1_", sig_df$feature_id),
    to = paste0("omics2_", sig_df$feature_id),
    weight = abs(sig_df$correlation),
    correlation = sig_df$correlation,
    stringsAsFactors = FALSE
  )

  g <- igraph::graph_from_data_frame(edges, directed = FALSE)

  # Network metrics
  metrics <- list(
    n_nodes = igraph::vcount(g),
    n_edges = igraph::ecount(g),
    density = igraph::edge_density(g),
    mean_weight = mean(edges$weight)
  )

  list(
    edges = sig_df,
    graph = g,
    metrics = metrics
  )
}

#' Save pairwise correlation results
save_pairwise_correlation_results <- function(pair_result, pair_name, config) {
  # Save correlation table
  save_table(
    pair_result$cor_df,
    paste0("crossomics_correlations_", pair_name, ".csv"),
    config
  )

  # Save partial correlations if available
  if (!is.null(pair_result$partial)) {
    save_table(
      pair_result$partial$partial_df,
      paste0("partial_correlations_", pair_name, ".csv"),
      config
    )
  }

  # Save network edges if available
  if (!is.null(pair_result$network) && !is.null(pair_result$network$edges)) {
    save_table(
      pair_result$network$edges,
      paste0("correlation_network_edges_", pair_name, ".csv"),
      config
    )
  }
}

#' Summarize correlation results across all pairs
summarize_correlation_results <- function(results, config) {
  # Filter to actual pair results (not summary)
  pair_names <- setdiff(names(results), "summary")

  summary_rows <- lapply(pair_names, function(pn) {
    pr <- results[[pn]]
    data.frame(
      pair = pn,
      omics1 = pr$omics1,
      omics2 = pr$omics2,
      n_features = pr$summary$n_features,
      n_samples = pr$n_samples,
      mean_correlation = round(pr$summary$mean_cor, 4),
      median_correlation = round(pr$summary$median_cor, 4),
      n_significant = pr$summary$n_significant,
      pct_positive = round(pr$summary$pct_positive, 1),
      stringsAsFactors = FALSE
    )
  })

  summary_df <- do.call(rbind, summary_rows)
  save_table(summary_df, "crossomics_correlation_summary.csv", config)

  summary_df
}

#' Plot correlation overview
plot_correlation_overview <- function(results, config) {
  pair_names <- setdiff(names(results), "summary")
  if (length(pair_names) == 0) return(NULL)

  # Combine all correlations for overview
  all_cors <- lapply(pair_names, function(pn) {
    pr <- results[[pn]]
    data.frame(
      pair = pn,
      correlation = pr$correlations[!is.na(pr$correlations)],
      stringsAsFactors = FALSE
    )
  })
  all_cors_df <- do.call(rbind, all_cors)

  # Density plot by pair
  p1 <- ggplot2::ggplot(all_cors_df, ggplot2::aes(x = correlation, fill = pair)) +
    ggplot2::geom_density(alpha = 0.5) +
    ggplot2::geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
    ggplot2::theme_minimal() +
    ggplot2::labs(
      title = "Cross-Omics Correlation Distributions",
      subtitle = "Feature-level correlations between omics layers",
      x = "Correlation",
      y = "Density",
      fill = "Omics Pair"
    ) +
    ggplot2::theme(legend.position = "bottom")

  save_plot(p1, "crossomics_correlation_density.png", config, width = 10, height = 6)

  # Box plot by pair
  p2 <- ggplot2::ggplot(all_cors_df, ggplot2::aes(x = pair, y = correlation, fill = pair)) +
    ggplot2::geom_boxplot(alpha = 0.7) +
    ggplot2::geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    ggplot2::theme_minimal() +
    ggplot2::labs(
      title = "Cross-Omics Correlation Summary",
      x = "Omics Pair",
      y = "Correlation"
    ) +
    ggplot2::theme(legend.position = "none",
                   axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))

  save_plot(p2, "crossomics_correlation_boxplot.png", config, width = 8, height = 6)

  list(density_plot = p1, boxplot = p2)
}

# =============================================================================
# 2. Sample-Level Concordance Analysis
# =============================================================================

#' Compute sample-level concordance across omics
#' @param harmonized List of harmonized omics data
#' @param metadata Sample metadata
#' @param fc Foundational config
#' @param config Full config
compute_sample_concordance <- function(harmonized, metadata, fc, config) {
  log_message("Computing sample-level concordance...")

  omics_names <- names(harmonized)
  results <- list()

  # Get common samples across all omics
  all_samples <- lapply(harmonized, function(h) colnames(h$normalized_matrix))
  common_samples <- Reduce(intersect, all_samples)

  if (length(common_samples) < 5) {
    log_message("Insufficient common samples (", length(common_samples), "). Skipping.")
    return(NULL)
  }

  log_message("  Analyzing ", length(common_samples), " samples across ",
              length(omics_names), " omics")

  # 1. Per-sample rank correlation across omics
  results$sample_rank_cors <- compute_sample_rank_correlations(
    harmonized, common_samples, fc
  )

  # 2. Sample clustering consistency (NMI, ARI)
  results$clustering_consistency <- compute_clustering_consistency(
    harmonized, common_samples, metadata, fc, config
  )

  # 3. Within-condition vs between-condition similarity
  if (!is.null(metadata)) {
    condition_col <- config$design$condition_column %||% "condition"
    if (condition_col %in% colnames(metadata)) {
      results$condition_similarity <- compute_condition_similarity(
        harmonized, common_samples, metadata, condition_col, fc, config
      )
    }
  }

  # 4. Consensus sample clustering
  results$consensus_clustering <- compute_consensus_clustering(
    harmonized, common_samples, fc, config
  )

  # 5. Identify discordant samples
  results$discordant_samples <- identify_discordant_samples(
    results, common_samples, fc, config
  )

  # Save and visualize
  save_sample_concordance_results(results, config)
  plot_sample_concordance(results, metadata, config)

  return(results)
}

#' Compute per-sample rank correlations
compute_sample_rank_correlations <- function(harmonized, common_samples, fc) {
  omics_names <- names(harmonized)
  n_samples <- length(common_samples)

  # For each sample, correlate its expression profile across omics
  # This uses highly variable features in each omics

  omics_matrices <- lapply(harmonized, function(h) {
    mat <- h$normalized_matrix[, common_samples, drop = FALSE]
    # Use top variable features
    vars <- apply(mat, 1, var, na.rm = TRUE)
    top_idx <- order(vars, decreasing = TRUE)[1:min(fc$top_variable_features, nrow(mat))]
    mat[top_idx, , drop = FALSE]
  })

  # Pairwise sample correlations per omics
  pairs <- combn(omics_names, 2, simplify = FALSE)

  sample_cors <- lapply(pairs, function(pair) {
    omics1 <- pair[1]
    omics2 <- pair[2]

    mat1 <- omics_matrices[[omics1]]
    mat2 <- omics_matrices[[omics2]]

    # Per-sample correlation (across features)
    # This requires matched features - use scaled values
    cors <- numeric(n_samples)
    names(cors) <- common_samples

    for (s in common_samples) {
      # Get ranks of each sample's expression
      r1 <- rank(mat1[, s], na.last = "keep")
      r2 <- rank(mat2[, s], na.last = "keep")

      # Correlate the sample's relative expression patterns
      # This measures if highly expressed genes in one omics are also high in the other
      # Actually, for this we need matched features - skip if not available
      cors[s] <- NA
    }

    # Alternative: correlate sample-sample distances
    dist1 <- as.matrix(dist(t(mat1)))
    dist2 <- as.matrix(dist(t(mat2)))

    mantel_cor <- cor(as.vector(dist1), as.vector(dist2), method = fc$correlation_method)

    list(
      pair = paste(pair, collapse = "_vs_"),
      mantel_correlation = mantel_cor
    )
  })

  # Summary
  mantel_cors <- sapply(sample_cors, function(x) x$mantel_correlation)
  names(mantel_cors) <- sapply(sample_cors, function(x) x$pair)

  log_message("  Sample distance correlations (Mantel): ",
              paste(names(mantel_cors), "=", round(mantel_cors, 3), collapse = ", "))

  list(
    mantel_correlations = mantel_cors,
    details = sample_cors
  )
}

#' Compute clustering consistency across omics (NMI, ARI)
compute_clustering_consistency <- function(harmonized, common_samples, metadata, fc, config) {
  log_message("  Computing clustering consistency...")

  omics_names <- names(harmonized)

  # Cluster samples in each omics
  cluster_results <- lapply(omics_names, function(omics_name) {
    mat <- harmonized[[omics_name]]$normalized_matrix[, common_samples, drop = FALSE]

    # PCA
    vars <- apply(mat, 1, var, na.rm = TRUE)
    top_idx <- order(vars, decreasing = TRUE)[1:min(1000, nrow(mat))]
    mat_sub <- mat[top_idx, ]
    mat_sub <- mat_sub[complete.cases(mat_sub), ]

    if (nrow(mat_sub) < 10) return(NULL)

    pca <- prcomp(t(mat_sub), scale. = TRUE, center = TRUE)

    # K-means clustering (k=3 or number of conditions if known)
    k <- 3
    if (!is.null(metadata)) {
      condition_col <- config$design$condition_column %||% "condition"
      if (condition_col %in% colnames(metadata)) {
        k <- length(unique(metadata[[condition_col]]))
      }
    }
    k <- min(k, floor(length(common_samples) / 2))
    k <- max(k, 2)

    km <- kmeans(pca$x[, 1:min(5, ncol(pca$x))], centers = k, nstart = 25)

    list(
      clusters = km$cluster,
      pca = pca,
      k = k
    )
  })
  names(cluster_results) <- omics_names

  # Remove NULL results
  cluster_results <- cluster_results[!sapply(cluster_results, is.null)]

  if (length(cluster_results) < 2) {
    log_message("  Insufficient omics for clustering comparison")
    return(NULL)
  }

  # Compute pairwise ARI and NMI
  pairs <- combn(names(cluster_results), 2, simplify = FALSE)

  ari_nmi <- lapply(pairs, function(pair) {
    c1 <- cluster_results[[pair[1]]]$clusters
    c2 <- cluster_results[[pair[2]]]$clusters

    # Adjusted Rand Index
    ari <- compute_ari(c1, c2)

    # Normalized Mutual Information
    nmi <- compute_nmi(c1, c2)

    list(
      pair = paste(pair, collapse = "_vs_"),
      ari = ari,
      nmi = nmi
    )
  })

  # Summary
  ari_values <- sapply(ari_nmi, function(x) x$ari)
  nmi_values <- sapply(ari_nmi, function(x) x$nmi)
  names(ari_values) <- names(nmi_values) <- sapply(ari_nmi, function(x) x$pair)

  log_message("  Clustering consistency (ARI): ",
              paste(names(ari_values), "=", round(ari_values, 3), collapse = ", "))

  list(
    ari = ari_values,
    nmi = nmi_values,
    cluster_results = cluster_results,
    details = ari_nmi
  )
}

#' Compute Adjusted Rand Index
compute_ari <- function(c1, c2) {
  # Use aricode if available, otherwise simple implementation
  if (requireNamespace("aricode", quietly = TRUE)) {
    return(aricode::ARI(c1, c2))
  }

  # Simple implementation
  n <- length(c1)
  tab <- table(c1, c2)

  sum_comb_a <- sum(choose(rowSums(tab), 2))
  sum_comb_b <- sum(choose(colSums(tab), 2))
  sum_comb <- sum(choose(tab, 2))

  expected <- (sum_comb_a * sum_comb_b) / choose(n, 2)
  max_index <- 0.5 * (sum_comb_a + sum_comb_b)

  if (max_index == expected) return(1)

  (sum_comb - expected) / (max_index - expected)
}

#' Compute Normalized Mutual Information
compute_nmi <- function(c1, c2) {
  if (requireNamespace("aricode", quietly = TRUE)) {
    return(aricode::NMI(c1, c2))
  }

  # Simple implementation
  tab <- table(c1, c2)
  n <- sum(tab)

  # Joint entropy
  p_joint <- tab / n
  p_joint <- p_joint[p_joint > 0]
  h_joint <- -sum(p_joint * log(p_joint))

  # Marginal entropies
  p1 <- table(c1) / n
  p2 <- table(c2) / n
  h1 <- -sum(p1 * log(p1))
  h2 <- -sum(p2 * log(p2))

  # Mutual information
  mi <- h1 + h2 - h_joint

  # Normalized
  if (h1 + h2 == 0) return(0)
  2 * mi / (h1 + h2)
}

#' Compute within-condition vs between-condition similarity
compute_condition_similarity <- function(harmonized, common_samples, metadata,
                                          condition_col, fc, config) {
  log_message("  Computing within vs between-condition similarity...")

  omics_names <- names(harmonized)
  conditions <- metadata[[condition_col]][match(common_samples, metadata$sample_id)]

  results <- lapply(omics_names, function(omics_name) {
    mat <- harmonized[[omics_name]]$normalized_matrix[, common_samples, drop = FALSE]

    # Compute sample correlation matrix
    cor_mat <- cor(mat, use = "pairwise.complete.obs")

    # Separate within and between condition correlations
    unique_cond <- unique(conditions)

    within_cors <- c()
    between_cors <- c()

    for (i in 1:(length(common_samples) - 1)) {
      for (j in (i + 1):length(common_samples)) {
        r <- cor_mat[i, j]
        if (is.na(r)) next

        if (conditions[i] == conditions[j]) {
          within_cors <- c(within_cors, r)
        } else {
          between_cors <- c(between_cors, r)
        }
      }
    }

    list(
      omics = omics_name,
      within_mean = mean(within_cors, na.rm = TRUE),
      within_sd = sd(within_cors, na.rm = TRUE),
      between_mean = mean(between_cors, na.rm = TRUE),
      between_sd = sd(between_cors, na.rm = TRUE),
      separation = mean(within_cors, na.rm = TRUE) - mean(between_cors, na.rm = TRUE)
    )
  })
  names(results) <- omics_names

  # Summary data frame
  summary_df <- do.call(rbind, lapply(results, function(r) {
    data.frame(
      omics = r$omics,
      within_condition_cor = round(r$within_mean, 4),
      between_condition_cor = round(r$between_mean, 4),
      separation = round(r$separation, 4),
      stringsAsFactors = FALSE
    )
  }))

  log_message("  Condition separation: ",
              paste(summary_df$omics, "=", round(summary_df$separation, 3), collapse = ", "))

  list(
    per_omics = results,
    summary = summary_df
  )
}

#' Compute consensus clustering across omics
compute_consensus_clustering <- function(harmonized, common_samples, fc, config) {
  log_message("  Computing consensus clustering...")

  # Check if ConsensusClusterPlus is available
  if (!requireNamespace("ConsensusClusterPlus", quietly = TRUE)) {
    log_message("  ConsensusClusterPlus not available. Skipping.")
    return(NULL)
  }

  omics_names <- names(harmonized)

  # Get PCA embeddings for each omics
  embeddings <- lapply(omics_names, function(omics_name) {
    mat <- harmonized[[omics_name]]$normalized_matrix[, common_samples, drop = FALSE]
    vars <- apply(mat, 1, var, na.rm = TRUE)
    top_idx <- order(vars, decreasing = TRUE)[1:min(1000, nrow(mat))]
    mat_sub <- mat[top_idx, ]
    mat_sub <- mat_sub[complete.cases(mat_sub), ]

    if (nrow(mat_sub) < 10) return(NULL)

    pca <- prcomp(t(mat_sub), scale. = TRUE, center = TRUE)
    pca$x[, 1:min(10, ncol(pca$x))]
  })
  names(embeddings) <- omics_names
  embeddings <- embeddings[!sapply(embeddings, is.null)]

  if (length(embeddings) < 2) return(NULL)

  # Combine embeddings
  combined <- do.call(cbind, embeddings)

  # Scale each omics contribution
  combined <- scale(combined)

  # Run consensus clustering
  result <- tryCatch({
    ConsensusClusterPlus::ConsensusClusterPlus(
      t(combined),
      maxK = min(6, floor(length(common_samples) / 3)),
      reps = 100,
      pItem = 0.8,
      pFeature = 1,
      clusterAlg = "hc",
      distance = "euclidean",
      seed = 42,
      plot = NULL,
      verbose = FALSE
    )
  }, error = function(e) {
    log_message("  Consensus clustering failed: ", e$message)
    NULL
  })

  if (is.null(result)) return(NULL)

  # Get best K based on delta area
  # Simple heuristic: use K with good stability
  k_best <- 2
  for (k in 3:min(6, length(result))) {
    if (!is.null(result[[k]])) {
      if (mean(result[[k]]$consensusMatrix) > 0.7) {
        k_best <- k
      }
    }
  }

  list(
    k_best = k_best,
    clusters = result[[k_best]]$consensusClass,
    consensus_matrix = result[[k_best]]$consensusMatrix
  )
}

#' Identify discordant samples (different patterns across omics)
identify_discordant_samples <- function(results, common_samples, fc, config) {
  log_message("  Identifying discordant samples...")

  if (is.null(results$clustering_consistency)) {
    return(NULL)
  }

  cluster_results <- results$clustering_consistency$cluster_results
  if (length(cluster_results) < 2) return(NULL)

  omics_names <- names(cluster_results)

  # For each sample, check if it clusters consistently
  discordance_scores <- sapply(common_samples, function(s) {
    clusters <- sapply(cluster_results, function(cr) cr$clusters[s])

    # Count how many omics pairs disagree
    pairs <- combn(omics_names, 2, simplify = FALSE)
    n_disagree <- sum(sapply(pairs, function(pair) {
      clusters[pair[1]] != clusters[pair[2]]
    }))

    n_disagree / length(pairs)
  })

  # Identify highly discordant samples (>50% disagreement)
  discordant_samples <- names(discordance_scores)[discordance_scores > 0.5]

  discordance_df <- data.frame(
    sample_id = common_samples,
    discordance_score = discordance_scores,
    is_discordant = discordance_scores > 0.5,
    stringsAsFactors = FALSE
  )

  log_message("  Found ", length(discordant_samples), " discordant samples")

  list(
    discordance_df = discordance_df,
    discordant_samples = discordant_samples,
    n_discordant = length(discordant_samples)
  )
}

#' Save sample concordance results
save_sample_concordance_results <- function(results, config) {
  # Save clustering consistency
  if (!is.null(results$clustering_consistency)) {
    consistency_df <- data.frame(
      pair = names(results$clustering_consistency$ari),
      ARI = results$clustering_consistency$ari,
      NMI = results$clustering_consistency$nmi,
      stringsAsFactors = FALSE
    )
    save_table(consistency_df, "sample_clustering_consistency.csv", config)
  }

  # Save condition similarity
  if (!is.null(results$condition_similarity)) {
    save_table(results$condition_similarity$summary,
               "sample_condition_similarity.csv", config)
  }

  # Save discordant samples
  if (!is.null(results$discordant_samples)) {
    save_table(results$discordant_samples$discordance_df,
               "sample_discordance.csv", config)
  }

  # Overall summary
  summary_df <- data.frame(
    metric = c("mantel_correlation", "mean_ari", "mean_nmi", "n_discordant"),
    value = c(
      mean(results$sample_rank_cors$mantel_correlations, na.rm = TRUE),
      mean(results$clustering_consistency$ari, na.rm = TRUE),
      mean(results$clustering_consistency$nmi, na.rm = TRUE),
      results$discordant_samples$n_discordant %||% NA
    ),
    stringsAsFactors = FALSE
  )
  save_table(summary_df, "sample_concordance_summary.csv", config)
}

#' Plot sample concordance
plot_sample_concordance <- function(results, metadata, config) {
  # Plot 1: Clustering consistency bar plot
  if (!is.null(results$clustering_consistency)) {
    df <- data.frame(
      pair = names(results$clustering_consistency$ari),
      ARI = results$clustering_consistency$ari,
      NMI = results$clustering_consistency$nmi
    )
    df_long <- tidyr::pivot_longer(df, cols = c(ARI, NMI),
                                    names_to = "metric", values_to = "value")

    p1 <- ggplot2::ggplot(df_long, ggplot2::aes(x = pair, y = value, fill = metric)) +
      ggplot2::geom_bar(stat = "identity", position = "dodge") +
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = "Sample Clustering Consistency Across Omics",
        subtitle = "Higher values indicate more consistent sample clustering",
        x = "Omics Pair",
        y = "Score",
        fill = "Metric"
      ) +
      ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) +
      ggplot2::ylim(0, 1)

    save_plot(p1, "sample_clustering_consistency.png", config, width = 8, height = 6)
  }

  # Plot 2: Condition separation
  if (!is.null(results$condition_similarity)) {
    df <- results$condition_similarity$summary

    p2 <- ggplot2::ggplot(df, ggplot2::aes(x = omics, y = separation, fill = omics)) +
      ggplot2::geom_bar(stat = "identity") +
      ggplot2::geom_hline(yintercept = 0, linetype = "dashed") +
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = "Within vs Between-Condition Similarity",
        subtitle = "Positive = samples cluster by condition within omics",
        x = "Omics",
        y = "Separation (within - between)"
      ) +
      ggplot2::theme(legend.position = "none")

    save_plot(p2, "sample_condition_separation.png", config, width = 6, height = 5)
  }

  # Plot 3: Discordance distribution
  if (!is.null(results$discordant_samples)) {
    df <- results$discordant_samples$discordance_df

    p3 <- ggplot2::ggplot(df, ggplot2::aes(x = discordance_score)) +
      ggplot2::geom_histogram(bins = 20, fill = "steelblue", color = "white") +
      ggplot2::geom_vline(xintercept = 0.5, color = "red", linetype = "dashed") +
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = "Sample Discordance Distribution",
        subtitle = "Samples right of red line cluster differently across omics",
        x = "Discordance Score",
        y = "Count"
      )

    save_plot(p3, "sample_discordance_distribution.png", config, width = 8, height = 5)
  }
}

# =============================================================================
# 3. Pathway Overlap Analysis
# =============================================================================

#' Analyze pathway overlap across omics
#' @param harmonized List of harmonized omics data
#' @param gene_mapping Gene mapping table
#' @param fc Foundational config
#' @param config Full config
analyze_pathway_overlap <- function(harmonized, gene_mapping, fc, config) {
  log_message("Analyzing pathway overlap across omics...")

  omics_names <- names(harmonized)

  # Check if enrichment results are available (from single-omics pipelines)
  enrichment_available <- sapply(harmonized, function(h) {
    !is.null(h$pathway_results) || !is.null(h$enrichment_results)
  })

  if (!any(enrichment_available)) {
    log_message("  No pre-computed pathway results available.")
    log_message("  Running basic enrichment on DE/DA results...")

    # Run enrichment for each omics with DE/DA results
    pathway_results <- run_basic_enrichment(harmonized, gene_mapping, fc, config)
  } else {
    # Use pre-computed results
    pathway_results <- lapply(names(enrichment_available)[enrichment_available], function(on) {
      h <- harmonized[[on]]
      list(
        omics = on,
        pathways = h$pathway_results %||% h$enrichment_results
      )
    })
    names(pathway_results) <- names(enrichment_available)[enrichment_available]
  }

  if (length(pathway_results) < 2) {
    log_message("  Insufficient omics with pathway results for overlap analysis")
    return(NULL)
  }

  # Compare pathway enrichments
  results <- list()

  # 1. Pathway overlap matrix (Jaccard similarity)
  results$overlap_matrix <- compute_pathway_overlap_matrix(pathway_results, fc)

  # 2. Shared vs omics-specific pathways
  results$shared_specific <- identify_shared_specific_pathways(pathway_results, fc)

  # 3. Pathway direction concordance
  results$direction_concordance <- compute_pathway_direction_concordance(pathway_results, fc)

  # Save and visualize
  save_pathway_overlap_results(results, config)
  plot_pathway_overlap(results, config)

  return(results)
}

#' Run basic enrichment for omics with DE/DA results
run_basic_enrichment <- function(harmonized, gene_mapping, fc, config) {
  if (!requireNamespace("clusterProfiler", quietly = TRUE)) {
    log_message("  clusterProfiler not available. Skipping enrichment.")
    return(list())
  }

  omics_names <- names(harmonized)

  results <- lapply(omics_names, function(omics_name) {
    h <- harmonized[[omics_name]]
    de_table <- h$de_table %||% h$da_table

    if (is.null(de_table)) return(NULL)

    # Get significant genes
    padj_col <- intersect(c("padj", "adj.P.Val", "FDR"), colnames(de_table))[1]
    if (is.na(padj_col)) return(NULL)

    sig_genes <- de_table$gene_symbol[de_table[[padj_col]] < 0.05]
    sig_genes <- sig_genes[!is.na(sig_genes) & sig_genes != ""]

    if (length(sig_genes) < 10) return(NULL)

    # Run GO enrichment
    enrich_result <- tryCatch({
      clusterProfiler::enrichGO(
        gene = sig_genes,
        OrgDb = "org.Hs.eg.db",
        keyType = "SYMBOL",
        ont = "BP",
        pvalueCutoff = 0.05,
        qvalueCutoff = 0.1
      )
    }, error = function(e) NULL)

    if (is.null(enrich_result) || nrow(as.data.frame(enrich_result)) == 0) {
      return(NULL)
    }

    enrich_df <- as.data.frame(enrich_result)

    list(
      omics = omics_name,
      pathways = enrich_df,
      sig_genes = sig_genes
    )
  })
  names(results) <- omics_names
  results <- results[!sapply(results, is.null)]

  results
}

#' Compute pathway overlap matrix (Jaccard similarity)
compute_pathway_overlap_matrix <- function(pathway_results, fc) {
  omics_names <- names(pathway_results)
  n_omics <- length(omics_names)

  # Get significant pathways per omics
  sig_pathways <- lapply(pathway_results, function(pr) {
    df <- pr$pathways
    padj_col <- intersect(c("p.adjust", "qvalue", "padj"), colnames(df))[1]
    if (is.na(padj_col)) return(character(0))

    term_col <- intersect(c("ID", "Description", "pathway"), colnames(df))[1]
    if (is.na(term_col)) return(character(0))

    df[[term_col]][df[[padj_col]] < fc$fdr_threshold]
  })

  # Compute Jaccard similarity matrix
  jaccard_mat <- matrix(0, n_omics, n_omics)
  rownames(jaccard_mat) <- colnames(jaccard_mat) <- omics_names

  for (i in 1:n_omics) {
    for (j in 1:n_omics) {
      a <- sig_pathways[[i]]
      b <- sig_pathways[[j]]

      if (length(a) == 0 || length(b) == 0) {
        jaccard_mat[i, j] <- 0
      } else {
        intersection <- length(intersect(a, b))
        union_size <- length(union(a, b))
        jaccard_mat[i, j] <- intersection / union_size
      }
    }
  }

  # Hypergeometric test for overlap significance
  overlap_tests <- list()
  pairs <- combn(omics_names, 2, simplify = FALSE)

  # Get universe size (union of all pathways)
  all_pathways <- unique(unlist(sig_pathways))
  universe_size <- length(all_pathways)

  for (pair in pairs) {
    a <- sig_pathways[[pair[1]]]
    b <- sig_pathways[[pair[2]]]

    if (length(a) > 0 && length(b) > 0 && universe_size > 0) {
      overlap <- length(intersect(a, b))

      # Hypergeometric test
      pval <- phyper(overlap - 1, length(a), universe_size - length(a),
                     length(b), lower.tail = FALSE)

      overlap_tests[[paste(pair, collapse = "_vs_")]] <- list(
        overlap = overlap,
        size1 = length(a),
        size2 = length(b),
        jaccard = jaccard_mat[pair[1], pair[2]],
        pvalue = pval
      )
    }
  }

  list(
    jaccard_matrix = jaccard_mat,
    significant_pathways = sig_pathways,
    overlap_tests = overlap_tests
  )
}

#' Identify shared vs omics-specific pathways
identify_shared_specific_pathways <- function(pathway_results, fc) {
  omics_names <- names(pathway_results)

  # Get significant pathways per omics
  sig_pathways <- lapply(pathway_results, function(pr) {
    df <- pr$pathways
    padj_col <- intersect(c("p.adjust", "qvalue", "padj"), colnames(df))[1]
    term_col <- intersect(c("ID", "Description", "pathway"), colnames(df))[1]

    if (is.na(padj_col) || is.na(term_col)) return(character(0))
    df[[term_col]][df[[padj_col]] < fc$fdr_threshold]
  })

  # All pathways across all omics
  all_pathways <- unique(unlist(sig_pathways))

  if (length(all_pathways) == 0) {
    return(NULL)
  }

  # Classify each pathway
  pathway_classification <- data.frame(
    pathway = all_pathways,
    stringsAsFactors = FALSE
  )

  for (omics in omics_names) {
    pathway_classification[[omics]] <- all_pathways %in% sig_pathways[[omics]]
  }

  # Number of omics enriched
  pathway_classification$n_omics <- rowSums(pathway_classification[, omics_names, drop = FALSE])

  # Classification
  pathway_classification$category <- ifelse(
    pathway_classification$n_omics == length(omics_names), "shared_all",
    ifelse(pathway_classification$n_omics > 1, "shared_some", "omics_specific")
  )

  # Identify which omics for specific pathways
  pathway_classification$specific_to <- apply(
    pathway_classification[, omics_names, drop = FALSE], 1, function(row) {
      if (sum(row) == 1) {
        omics_names[row]
      } else {
        NA
      }
    }
  )

  # Summary
  summary_df <- data.frame(
    category = c("shared_all", "shared_some", "omics_specific"),
    count = c(
      sum(pathway_classification$category == "shared_all"),
      sum(pathway_classification$category == "shared_some"),
      sum(pathway_classification$category == "omics_specific")
    ),
    stringsAsFactors = FALSE
  )

  log_message("  Pathway classification: ",
              sum(pathway_classification$category == "shared_all"), " shared by all, ",
              sum(pathway_classification$category == "omics_specific"), " omics-specific")

  list(
    classification = pathway_classification,
    summary = summary_df,
    shared_pathways = all_pathways[pathway_classification$category != "omics_specific"]
  )
}

#' Compute pathway direction concordance
compute_pathway_direction_concordance <- function(pathway_results, fc) {
  # This requires NES or direction information from GSEA-style enrichment
  # For ORA, we can use the proportion of up/down genes

  omics_names <- names(pathway_results)

  # Check if we have direction information
  has_direction <- sapply(pathway_results, function(pr) {
    "NES" %in% colnames(pr$pathways) || "direction" %in% colnames(pr$pathways)
  })

  if (!any(has_direction)) {
    log_message("  No direction information available for pathway concordance")
    return(NULL)
  }

  # Get pathways with direction
  pathway_directions <- lapply(pathway_results, function(pr) {
    df <- pr$pathways

    if ("NES" %in% colnames(df)) {
      term_col <- intersect(c("ID", "Description", "pathway"), colnames(df))[1]
      data.frame(
        pathway = df[[term_col]],
        direction = sign(df$NES),
        stringsAsFactors = FALSE
      )
    } else if ("direction" %in% colnames(df)) {
      term_col <- intersect(c("ID", "Description", "pathway"), colnames(df))[1]
      data.frame(
        pathway = df[[term_col]],
        direction = ifelse(df$direction == "up", 1, -1),
        stringsAsFactors = FALSE
      )
    } else {
      NULL
    }
  })
  pathway_directions <- pathway_directions[!sapply(pathway_directions, is.null)]

  if (length(pathway_directions) < 2) {
    return(NULL)
  }

  # Find common pathways and check direction concordance
  common_pathways <- Reduce(intersect, lapply(pathway_directions, function(x) x$pathway))

  if (length(common_pathways) == 0) {
    return(NULL)
  }

  # Build direction matrix
  direction_mat <- matrix(NA, length(common_pathways), length(pathway_directions))
  rownames(direction_mat) <- common_pathways
  colnames(direction_mat) <- names(pathway_directions)

  for (omics in names(pathway_directions)) {
    pd <- pathway_directions[[omics]]
    idx <- match(common_pathways, pd$pathway)
    direction_mat[, omics] <- pd$direction[idx]
  }

  # Concordance: same direction across all omics
  concordance <- apply(direction_mat, 1, function(row) {
    row <- row[!is.na(row)]
    if (length(row) < 2) return(NA)
    all(row == row[1])
  })

  concordance_df <- data.frame(
    pathway = common_pathways,
    concordant = concordance,
    stringsAsFactors = FALSE
  )

  pct_concordant <- 100 * mean(concordance, na.rm = TRUE)
  log_message("  Pathway direction concordance: ", round(pct_concordant, 1), "%")

  list(
    direction_matrix = direction_mat,
    concordance = concordance_df,
    pct_concordant = pct_concordant
  )
}

#' Save pathway overlap results
save_pathway_overlap_results <- function(results, config) {
  if (!is.null(results$overlap_matrix)) {
    # Save Jaccard matrix
    jaccard_df <- as.data.frame(results$overlap_matrix$jaccard_matrix)
    jaccard_df$omics <- rownames(jaccard_df)
    save_table(jaccard_df, "pathway_overlap_jaccard.csv", config)

    # Save overlap tests
    if (length(results$overlap_matrix$overlap_tests) > 0) {
      tests_df <- do.call(rbind, lapply(names(results$overlap_matrix$overlap_tests), function(n) {
        t <- results$overlap_matrix$overlap_tests[[n]]
        data.frame(
          pair = n,
          overlap = t$overlap,
          size1 = t$size1,
          size2 = t$size2,
          jaccard = round(t$jaccard, 4),
          pvalue = t$pvalue,
          stringsAsFactors = FALSE
        )
      }))
      save_table(tests_df, "pathway_overlap_tests.csv", config)
    }
  }

  if (!is.null(results$shared_specific)) {
    save_table(results$shared_specific$classification,
               "pathway_shared_specific.csv", config)
  }

  if (!is.null(results$direction_concordance)) {
    save_table(results$direction_concordance$concordance,
               "pathway_direction_concordance.csv", config)
  }
}

#' Plot pathway overlap
plot_pathway_overlap <- function(results, config) {
  # Plot 1: Jaccard similarity heatmap
  if (!is.null(results$overlap_matrix)) {
    jaccard_mat <- results$overlap_matrix$jaccard_matrix

    # Convert to long format for ggplot
    jaccard_df <- as.data.frame(as.table(jaccard_mat))
    colnames(jaccard_df) <- c("Omics1", "Omics2", "Jaccard")

    p1 <- ggplot2::ggplot(jaccard_df, ggplot2::aes(x = Omics1, y = Omics2, fill = Jaccard)) +
      ggplot2::geom_tile() +
      ggplot2::geom_text(ggplot2::aes(label = round(Jaccard, 2)), color = "white", size = 4) +
      ggplot2::scale_fill_gradient(low = "white", high = "steelblue", limits = c(0, 1)) +
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = "Pathway Overlap Across Omics",
        subtitle = "Jaccard similarity of enriched pathways",
        x = "", y = "",
        fill = "Jaccard\nSimilarity"
      ) +
      ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))

    save_plot(p1, "pathway_overlap_heatmap.png", config, width = 7, height = 6)
  }

  # Plot 2: UpSet plot for pathway membership
  if (!is.null(results$shared_specific) &&
      requireNamespace("UpSetR", quietly = TRUE)) {

    classification <- results$shared_specific$classification
    omics_names <- setdiff(colnames(classification),
                           c("pathway", "n_omics", "category", "specific_to"))

    if (length(omics_names) >= 2 && nrow(classification) >= 5) {
      # Convert to list format for UpSetR
      pathway_sets <- lapply(omics_names, function(on) {
        classification$pathway[classification[[on]]]
      })
      names(pathway_sets) <- omics_names

      # Create UpSet plot
      png(file.path(config$output$output_dir, "plots", "pathway_overlap_upset.png"),
          width = 10, height = 6, units = "in", res = 300)

      tryCatch({
        print(UpSetR::upset(
          UpSetR::fromList(pathway_sets),
          order.by = "freq",
          main.bar.color = "steelblue",
          sets.bar.color = "darkgray",
          text.scale = 1.2
        ))
      }, error = function(e) {
        log_message("  UpSet plot failed: ", e$message)
      })

      dev.off()
    }
  }

  # Plot 3: Shared vs specific pie chart
  if (!is.null(results$shared_specific)) {
    summary_df <- results$shared_specific$summary

    p3 <- ggplot2::ggplot(summary_df, ggplot2::aes(x = "", y = count, fill = category)) +
      ggplot2::geom_bar(stat = "identity", width = 1) +
      ggplot2::coord_polar("y", start = 0) +
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = "Pathway Classification",
        fill = "Category"
      ) +
      ggplot2::scale_fill_manual(values = c("shared_all" = "#2166ac",
                                             "shared_some" = "#67a9cf",
                                             "omics_specific" = "#d1e5f0"))

    save_plot(p3, "pathway_classification_pie.png", config, width = 7, height = 6)
  }
}

# =============================================================================
# 4. Cross-Omics Module Detection
# =============================================================================

#' Find cross-omics co-expression modules
#' @param harmonized List of harmonized omics data
#' @param gene_mapping Gene mapping table
#' @param fc Foundational config
#' @param config Full config
find_crossomics_modules <- function(harmonized, gene_mapping, fc, config) {
  log_message("Finding cross-omics co-expression modules...")

  # Check if WGCNA is available
  if (!requireNamespace("WGCNA", quietly = TRUE)) {
    log_message("  WGCNA not available. Skipping module detection.")
    return(NULL)
  }

  omics_names <- names(harmonized)

  # Get common samples
  all_samples <- lapply(harmonized, function(h) colnames(h$normalized_matrix))
  common_samples <- Reduce(intersect, all_samples)

  if (length(common_samples) < 10) {
    log_message("  Insufficient common samples for module detection")
    return(NULL)
  }

  # Map features to common identifiers across omics
  # For now, concatenate features from all omics with omics prefix
  combined_data <- list()
  feature_info <- data.frame()

  for (omics in omics_names) {
    mat <- harmonized[[omics]]$normalized_matrix[, common_samples, drop = FALSE]

    # Use top variable features
    vars <- apply(mat, 1, var, na.rm = TRUE)
    top_idx <- order(vars, decreasing = TRUE)[1:min(fc$top_variable_features, nrow(mat))]
    mat_sub <- mat[top_idx, ]

    # Prefix feature names
    rownames(mat_sub) <- paste0(omics, "_", rownames(mat_sub))

    combined_data[[omics]] <- mat_sub

    # Track feature info
    feature_info <- rbind(feature_info, data.frame(
      feature_id = rownames(mat_sub),
      omics = omics,
      original_id = gsub(paste0("^", omics, "_"), "", rownames(mat_sub)),
      stringsAsFactors = FALSE
    ))
  }

  # Combine matrices
  combined_mat <- do.call(rbind, combined_data)

  # Remove features with missing values
  combined_mat <- combined_mat[complete.cases(combined_mat), ]

  if (nrow(combined_mat) < 100) {
    log_message("  Insufficient features after filtering for module detection")
    return(NULL)
  }

  log_message("  Running WGCNA on ", nrow(combined_mat), " features across ",
              length(common_samples), " samples")

  # Transpose for WGCNA (samples in rows)
  expr_data <- t(combined_mat)

  # Pick soft threshold
  powers <- c(1:10, seq(12, 20, 2))
  sft <- tryCatch({
    WGCNA::pickSoftThreshold(
      expr_data,
      powerVector = powers,
      verbose = 0
    )
  }, error = function(e) NULL)

  if (is.null(sft)) {
    log_message("  Soft threshold selection failed")
    return(NULL)
  }

  # Use recommended power or default
  soft_power <- sft$powerEstimate
  if (is.na(soft_power)) {
    soft_power <- 6
    log_message("  Using default soft power: ", soft_power)
  } else {
    log_message("  Selected soft power: ", soft_power)
  }

  # Build network and detect modules
  net <- tryCatch({
    WGCNA::blockwiseModules(
      expr_data,
      power = soft_power,
      TOMType = "unsigned",
      minModuleSize = 30,
      mergeCutHeight = 0.25,
      numericLabels = TRUE,
      verbose = 0
    )
  }, error = function(e) {
    log_message("  Module detection failed: ", e$message)
    NULL
  })

  if (is.null(net)) return(NULL)

  # Process results
  module_labels <- net$colors
  module_colors <- WGCNA::labels2colors(module_labels)

  # Create module membership table
  module_df <- data.frame(
    feature_id = colnames(expr_data),
    module_number = module_labels,
    module_color = module_colors,
    stringsAsFactors = FALSE
  )

  # Add omics information
  module_df <- merge(module_df, feature_info, by = "feature_id", all.x = TRUE)

  # Module summary
  module_summary <- table(module_df$module_number, module_df$omics)

  # Calculate omics composition per module
  module_composition <- as.data.frame.matrix(module_summary)
  module_composition$module <- rownames(module_composition)
  module_composition$total <- rowSums(module_composition[, omics_names])

  # Identify cross-omics modules (have features from multiple omics)
  n_omics_per_module <- apply(module_composition[, omics_names], 1, function(x) sum(x > 0))
  crossomics_modules <- names(n_omics_per_module)[n_omics_per_module > 1]

  log_message("  Detected ", length(unique(module_labels)), " modules, ",
              length(crossomics_modules), " contain features from multiple omics")

  # Module eigengenes
  ME <- net$MEs
  colnames(ME) <- gsub("^ME", "module_", colnames(ME))

  # Save results
  save_table(module_df, "crossomics_modules.csv", config)
  save_table(module_composition, "crossomics_module_composition.csv", config)

  ME_df <- as.data.frame(ME)
  ME_df$sample_id <- rownames(ME_df)
  save_table(ME_df, "crossomics_module_eigengenes.csv", config)

  # Visualizations
  plot_module_composition(module_composition, omics_names, config)

  list(
    module_assignments = module_df,
    module_composition = module_composition,
    module_eigengenes = ME,
    n_modules = length(unique(module_labels)),
    n_crossomics = length(crossomics_modules),
    soft_power = soft_power
  )
}

#' Plot module composition
plot_module_composition <- function(module_composition, omics_names, config) {
  # Prepare data for stacked bar plot
  mc_long <- tidyr::pivot_longer(
    module_composition,
    cols = tidyr::all_of(omics_names),
    names_to = "omics",
    values_to = "count"
  )

  # Filter out grey module (unassigned)
  mc_long <- mc_long[mc_long$module != "0", ]

  if (nrow(mc_long) == 0) return(NULL)

  p <- ggplot2::ggplot(mc_long, ggplot2::aes(x = module, y = count, fill = omics)) +
    ggplot2::geom_bar(stat = "identity", position = "stack") +
    ggplot2::theme_minimal() +
    ggplot2::labs(
      title = "Cross-Omics Module Composition",
      subtitle = "Features per omics in each detected module",
      x = "Module",
      y = "Number of Features",
      fill = "Omics"
    ) +
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))

  save_plot(p, "crossomics_module_composition.png", config, width = 10, height = 6)
}

# =============================================================================
# Summary Function
# =============================================================================

#' Summarize foundational analysis results
summarize_foundational_results <- function(results, config) {
  log_message("Generating foundational analysis summary...")

  summary_list <- list()

  # Feature correlations summary
  if (!is.null(results$feature_correlations)) {
    cor_summary <- results$feature_correlations$summary
    if (!is.null(cor_summary)) {
      summary_list$correlations <- list(
        n_pairs_analyzed = nrow(cor_summary),
        mean_correlation = mean(cor_summary$mean_correlation, na.rm = TRUE),
        total_significant = sum(cor_summary$n_significant, na.rm = TRUE)
      )
    }
  }

  # Sample concordance summary
  if (!is.null(results$sample_concordance)) {
    sc <- results$sample_concordance
    summary_list$sample_concordance <- list(
      mean_ari = mean(sc$clustering_consistency$ari, na.rm = TRUE),
      mean_nmi = mean(sc$clustering_consistency$nmi, na.rm = TRUE),
      n_discordant = sc$discordant_samples$n_discordant %||% NA
    )
  }

  # Pathway overlap summary
  if (!is.null(results$pathway_overlap)) {
    po <- results$pathway_overlap
    if (!is.null(po$shared_specific)) {
      summary_list$pathway_overlap <- list(
        n_shared_all = sum(po$shared_specific$classification$category == "shared_all"),
        n_omics_specific = sum(po$shared_specific$classification$category == "omics_specific"),
        mean_jaccard = mean(po$overlap_matrix$jaccard_matrix[upper.tri(po$overlap_matrix$jaccard_matrix)])
      )
    }
  }

  # Cross-omics modules summary
  if (!is.null(results$crossomics_modules)) {
    cm <- results$crossomics_modules
    summary_list$modules <- list(
      n_modules = cm$n_modules,
      n_crossomics = cm$n_crossomics
    )
  }

  # Save summary
  summary_df <- data.frame(
    category = names(summary_list),
    stringsAsFactors = FALSE
  )

  # Flatten to data frame
  flat_summary <- do.call(rbind, lapply(names(summary_list), function(cat) {
    s <- summary_list[[cat]]
    data.frame(
      category = cat,
      metric = names(s),
      value = unlist(s),
      stringsAsFactors = FALSE
    )
  }))

  save_table(flat_summary, "foundational_analysis_summary.csv", config)

  log_message("=== Foundational Analysis Summary ===")
  for (cat in names(summary_list)) {
    log_message("  ", cat, ": ", paste(names(summary_list[[cat]]), "=",
                                        round(unlist(summary_list[[cat]]), 3),
                                        collapse = ", "))
  }

  summary_list
}
