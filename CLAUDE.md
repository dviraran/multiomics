# Claude Context for Multi-Omics Pipelines

This file provides context for Claude (AI assistant) when working on this repository.

## Project Overview

This repository contains four interconnected R pipelines for omics data analysis, all built with the `{targets}` framework for reproducibility. The pipelines were developed to provide a complete analysis ecosystem from raw data to biological insights.

## Architecture Decisions

### Why {targets}?

- **Reproducibility**: Automatic dependency tracking ensures results are always up-to-date
- **Efficiency**: Only re-runs steps when inputs change
- **Transparency**: `tar_visnetwork()` visualizes the entire pipeline DAG
- **Caching**: Results stored in `_targets/` for fast re-access

### Modular Design

Each pipeline follows the same structure:
- `config.yml` - All parameters in one place, no hardcoded values in R code
- `R/` directory - One file per logical stage (ingestion → QC → normalization → analysis → enrichment)
- `_targets.R` - Pipeline orchestration only, calls functions from R/
- `reports/` - R Markdown templates that pull from targets results

### Non-Model Organism Support

All pipelines support organisms without Bioconductor annotation packages:
- Custom gene mapping files (CSV with ID columns)
- Custom GMT files for pathway enrichment
- No hardcoded assumptions about human/mouse

## Pipeline-Specific Notes

### rnaseq_pipeline

- Uses DESeq2 for normalization and differential expression
- Supports multiple contrasts defined in config
- fgsea for fast preranked GSEA
- Optional AI commentary via Claude/OpenAI APIs (see `scripts/`)

### proteomics_pipeline

- Supports multiple input formats: MaxQuant, FragPipe, DIA-NN, Spectronaut, generic
- MNAR (Missing Not At Random) aware imputation - important for proteomics
- VSN normalization recommended for variance stabilization

### metabolomics_pipeline

- Handles both untargeted (features) and targeted (known metabolites) workflows
- QC sample-based drift correction critical for large batches
- Blank subtraction for background removal

### multiomics_pipeline

- Requires at least 2 omics types
- MOFA2 for unsupervised exploration (what factors drive variation?)
- DIABLO for supervised classification (what features discriminate groups?)
- SNF optional for patient stratification
- Creates MultiAssayExperiment object for proper Bioconductor integration

## Common Tasks

### Adding a new analysis step

1. Create function in appropriate `R/XX_name.R` file
2. Add `tar_target()` call in `_targets.R`
3. Update config.yml if new parameters needed
4. Add section to `reports/analysis_report.Rmd`

### Modifying normalization/statistics

- Normalization: Look in `R/04_normalization.R` (or similar)
- Differential analysis: `R/06_differential.R` or `R/07_differential.R`
- All use config parameters, rarely need to change function code

### Debugging a failed target

```r
tar_load(failed_target)  # Load last successful upstream target
# Debug interactively
tar_invalidate(failed_target)  # Clear and re-run
```

## Data Expectations

### Sample metadata (all pipelines)

- Must have `sample_id` column (configurable name)
- Must have condition/group column for differential analysis
- Optional: batch column for batch correction

### Expression/abundance matrices

- Rows = features (genes/proteins/metabolites)
- Columns = samples
- Column names must match sample_id in metadata

## Output Conventions

- Tables: CSV format in `outputs/tables/` or `outputs/`
- Plots: PNG format in `outputs/plots/`
- Reports: HTML in `outputs/report/` or `outputs/`
- All outputs regenerated by pipeline (don't edit manually)

## Git Conventions

- Large outputs excluded via `.gitignore`
- `_targets/` cache never committed
- Example data files prefixed with `example_`
- User data files not tracked
